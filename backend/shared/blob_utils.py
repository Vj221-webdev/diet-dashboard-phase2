import os
import io
import pandas as pd
from azure.storage.blob import BlobServiceClient

CONN_STR = os.environ.get("BLOB_CONN_STR")
CONTAINER = os.environ.get("BLOB_CONTAINER", "datasets")
CSV_NAME = os.environ.get("BLOB_CSV_NAME", "All_Diets.csv")

# Column name mappings
CANON = {
    "diet_type": ["diet_type", "diet type", "diet", "type", "diettype"],
    "recipe": ["recipe", "name", "title", "item", "recipe_name", "recipename"],
    "protein": ["protein", "protein (g)", "protein(g)", "protein_g", "prot"],
    "carbs": ["carbs", "carbohydrates", "carbs (g)", "carbs(g)", "carb", "carbohydrate_g"],
    "fat": ["fat", "fat (g)", "fat(g)", "fats", "fat_g"],
    "calories": ["calories", "kcal", "kcals", "energy"]
}

def _canonicalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Standardize column names"""
    lower_to_orig = {c.strip().lower(): c for c in df.columns}
    rename_map = {}
    
    for target, variants in CANON.items():
        for v in variants:
            if v in lower_to_orig:
                rename_map[lower_to_orig[v]] = target
                break
    
    df = df.rename(columns=rename_map)
    
    # Ensure required columns exist
    for req in ["diet_type", "recipe", "protein", "carbs", "fat", "calories"]:
        if req not in df.columns:
            if req in ["protein", "carbs", "fat", "calories"]:
                df[req] = 0.0
            else:
                df[req] = ""
    
    # Convert to proper types
    for num in ["protein", "carbs", "fat", "calories"]:
        df[num] = pd.to_numeric(df[num], errors="coerce").fillna(0.0)
    
    # Calculate calories if missing
    if df["calories"].sum() == 0:
        df["calories"] = (4 * df["protein"] + 4 * df["carbs"] + 9 * df["fat"]).round(1)
    
    df["diet_type"] = df["diet_type"].astype(str)
    df["recipe"] = df["recipe"].astype(str)
    
    return df


def load_dataset() -> pd.DataFrame:
    """Load and clean the CSV from Azure Blob Storage"""
    if not CONN_STR:
        raise ValueError("BLOB_CONN_STR environment variable not set")
    
    # Connect to blob storage
    service_client = BlobServiceClient.from_connection_string(CONN_STR)
    blob_client = service_client.get_blob_client(container=CONTAINER, blob=CSV_NAME)
    
    # Download and read CSV
    data = blob_client.download_blob().readall()
    df = pd.read_csv(io.BytesIO(data))
    
    # Canonicalize columns
    df = _canonicalize_columns(df)
    
    return df